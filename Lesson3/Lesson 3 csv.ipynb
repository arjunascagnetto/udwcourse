{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "The following things should be done:\n",
    "- check if the field \"productionStartYear\" contains a year\n",
    "- check if the year is in range 1886-2014\n",
    "- convert the value of the field to be just a year (not full datetime)\n",
    "- the rest of the fields and values should stay the same\n",
    "- if the value of the field is a valid year in the range as described above,\n",
    "  write that line to the output_good file\n",
    "- if the value of the field is not a valid year as described above, \n",
    "  write that line to the output_bad file\n",
    "- discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "- you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "  They will take care of dealing with the header.\n",
    "\n",
    "You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pprint\n",
    "\n",
    "input_file = 'data/autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 http://dbpedia.org/ontology/productionStartYear\n",
      "1 XMLSchema#gYear\n",
      "2 http://www.w3.org/2001/XMLSchema#gYear\n",
      "3 1989-01-01T00:00:00+02:00\n",
      "4 1969-01-01T00:00:00+02:00\n",
      "5 1957-01-01T00:00:00+02:00\n",
      "6 1959-01-01T00:00:00+02:00\n",
      "7 2108-01-01T00:00:00+02:00\n",
      "8 1936-01-01T00:00:00+02:00\n",
      "9 1953-01-01T00:00:00+02:00\n",
      "10 2002-01-01T00:00:00+02:00\n",
      "11 2002-01-01T00:00:00+02:00\n",
      "12 1985-01-01T00:00:00+02:00\n",
      "13 1939-01-01T00:00:00+02:00\n",
      "14 1970-01-01T00:00:00+02:00\n",
      "15 1957-01-01T00:00:00+02:00\n",
      "16 1958-01-01T00:00:00+02:00\n",
      "17 1983-01-01T00:00:00+02:00\n",
      "18 1962-01-01T00:00:00+02:00\n",
      "19 1964-01-01T00:00:00+02:00\n",
      "20 0001-01-01T00:00:00+02:00\n",
      "21 1964-01-01T00:00:00+02:00\n",
      "22 1979-01-01T00:00:00+02:00\n",
      "23 1961-01-01T00:00:00+02:00\n",
      "24 1975-01-01T00:00:00+02:00\n",
      "25 1953-01-01T00:00:00+02:00\n",
      "26 NULL\n",
      "27 1978-01-01T00:00:00+02:00\n",
      "28 1908-01-01T00:00:00+02:00\n",
      "29 1994-01-01T00:00:00+02:00\n",
      "30 1955-01-01T00:00:00+02:00\n",
      "31 1927-01-01T00:00:00+02:00\n",
      "32 1951-01-01T00:00:00+02:00\n",
      "33 1979-01-01T00:00:00+02:00\n",
      "34 NULL\n",
      "35 1955-01-01T00:00:00+02:00\n",
      "36 2002-01-01T00:00:00+02:00\n",
      "37 1985-01-01T00:00:00+02:00\n",
      "38 1968-01-01T00:00:00+02:00\n",
      "39 1979-01-01T00:00:00+02:00\n",
      "40 1975-01-01T00:00:00+02:00\n",
      "41 1994-01-01T00:00:00+02:00\n",
      "42 1956-01-01T00:00:00+02:00\n",
      "43 1968-01-01T00:00:00+02:00\n",
      "44 1977-01-01T00:00:00+02:00\n",
      "45 1983-01-01T00:00:00+02:00\n",
      "46 2001-01-01T00:00:00+02:00\n",
      "47 1959-01-01T00:00:00+02:00\n",
      "48 1956-01-01T00:00:00+02:00\n"
     ]
    }
   ],
   "source": [
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for i,row in enumerate(reader):\n",
    "        print i,row['productionStartYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t...to be discarded\n",
      "\t...to be discarded\n",
      "\t...to be discarded\n",
      "\t...to Good file 1989\n",
      "\t...to Good file 1969\n",
      "\t...to Good file 1957\n",
      "\t...to Good file 1959\n",
      "2108\n",
      "\t...to Good file 1936\n",
      "\t...to Good file 1953\n",
      "\t...to Good file 2002\n",
      "\t...to Good file 2002\n",
      "\t...to Good file 1985\n",
      "\t...to Good file 1939\n",
      "\t...to Good file 1970\n",
      "\t...to Good file 1957\n",
      "\t...to Good file 1958\n",
      "\t...to Good file 1983\n",
      "\t...to Good file 1962\n",
      "\t...to Good file 1964\n",
      "1\n",
      "\t...to Good file 1964\n",
      "\t...to Good file 1979\n",
      "\t...to Good file 1961\n",
      "\t...to Good file 1975\n",
      "\t...to Good file 1953\n",
      "\t...to Bad file\n",
      "\t...to Good file 1978\n",
      "\t...to Good file 1908\n",
      "\t...to Good file 1994\n",
      "\t...to Good file 1955\n",
      "\t...to Good file 1927\n",
      "\t...to Good file 1951\n",
      "\t...to Good file 1979\n",
      "\t...to Bad file\n",
      "\t...to Good file 1955\n",
      "\t...to Good file 2002\n",
      "\t...to Good file 1985\n",
      "\t...to Good file 1968\n",
      "\t...to Good file 1979\n",
      "\t...to Good file 1975\n",
      "\t...to Good file 1994\n",
      "\t...to Good file 1956\n",
      "\t...to Good file 1968\n",
      "\t...to Good file 1977\n",
      "\t...to Good file 1983\n",
      "\t...to Good file 2001\n",
      "\t...to Good file 1959\n",
      "\t...to Good file 1956\n"
     ]
    }
   ],
   "source": [
    "goods = []\n",
    "bads = []\n",
    "with open(input_file, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    header = reader.fieldnames\n",
    "    for i,row in enumerate(reader):\n",
    "        #print i,row['URI'],row['productionStartYear']\n",
    "        if 'dbpedia' in row['URI']:\n",
    "            dato = row['productionStartYear']\n",
    "            if re.match(r'[0-9]',dato):\n",
    "                #print dato,type(dato)\n",
    "                year = int(dato.split('-')[0])\n",
    "                #print year,type(year)\n",
    "                if 1886 <= year <= 2014:\n",
    "                    print '\\t...to Good file',year\n",
    "                    row['productionStartYear'] = year\n",
    "                    goods.append(row)\n",
    "                else:\n",
    "                    print '\\t...to Bad file'\n",
    "                    bads.append(row)\n",
    "            else :\n",
    "                print '\\t...to Bad file'\n",
    "                bads.append(row)\n",
    "        else:\n",
    "            print '\\t...to be discarded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 : 4\n"
     ]
    }
   ],
   "source": [
    "print len(goods),':',len(bads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989\n",
      "1969\n",
      "1957\n",
      "1959\n",
      "1936\n",
      "1953\n",
      "2002\n",
      "2002\n",
      "1985\n",
      "1939\n",
      "1970\n",
      "1957\n",
      "1958\n",
      "1983\n",
      "1962\n",
      "1964\n",
      "1964\n",
      "1979\n",
      "1961\n",
      "1975\n",
      "1953\n",
      "1978\n",
      "1908\n",
      "1994\n",
      "1955\n",
      "1927\n",
      "1951\n",
      "1979\n",
      "1955\n",
      "2002\n",
      "1985\n",
      "1968\n",
      "1979\n",
      "1975\n",
      "1994\n",
      "1956\n",
      "1968\n",
      "1977\n",
      "1983\n",
      "2001\n",
      "1959\n",
      "1956\n"
     ]
    }
   ],
   "source": [
    "for good in goods:\n",
    "    print good['productionStartYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108-01-01T00:00:00+02:00\n",
      "0001-01-01T00:00:00+02:00\n",
      "NULL\n",
      "NULL\n"
     ]
    }
   ],
   "source": [
    "for bad in bads:\n",
    "    print bad['productionStartYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'int'> 1989\n"
     ]
    }
   ],
   "source": [
    "r = datetime.strptime('1989-01-01T00:00:00+02:00'.split('T')[0], '%Y-%d-%m')\n",
    "year = r.year\n",
    "print type(year),year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match at 0x7f6513dae8b8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.match(u'[0-9]','1989-01-01T00:00:00+02:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # This is just an example on how you can use csv.DictWriter\n",
    "    # Remember that you have to output 2 files\n",
    "with open(output_good, \"w\") as g:\n",
    "    writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "    writer.writeheader()\n",
    "    for row in YOURDATA:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Teacher's Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_file(input_file, output_good, output_bad):\n",
    "    # store data into lists for output\n",
    "    data_good = []\n",
    "    data_bad = []\n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        for row in reader:\n",
    "            # validate URI value\n",
    "            if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                continue\n",
    "\n",
    "            ps_year = row['productionStartYear'][:4]\n",
    "            try: # use try/except to filter valid items\n",
    "                ps_year = int(ps_year)\n",
    "                row['productionStartYear'] = ps_year\n",
    "                if (ps_year >= 1886) and (ps_year <= 2014):\n",
    "                    data_good.append(row)\n",
    "                else:\n",
    "                    data_bad.append(row)\n",
    "            except ValueError: # non-numeric strings caught by exception\n",
    "                if ps_year == 'NULL':\n",
    "                    data_bad.append(row)\n",
    "\n",
    "    # Write processed data to output files\n",
    "    with open(output_good, \"w\") as good:\n",
    "        writer = csv.DictWriter(good, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_good:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    with open(output_bad, \"w\") as bad:\n",
    "        writer = csv.DictWriter(bad, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in data_bad:\n",
    "            writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
